import main.ast
import main.prelude
import main.token

function BuildKeywordTable():KeywordTable
	var table = KeywordTable.New
	
	table.names = new string[256]
	table.tokens = new TokenType[256]
	table.count = 0
	
	KeywordTableInsert(table, "import", TokenType.KImport)	
	KeywordTableInsert(table, "function", TokenType.KFunction)	
	KeywordTableInsert(table, "end", TokenType.KEnd)	
	KeywordTableInsert(table, "var", TokenType.KVar)	
	KeywordTableInsert(table, "field", TokenType.KField)	
	KeywordTableInsert(table, "new", TokenType.KNew)	
	KeywordTableInsert(table, "return", TokenType.KReturn)	
	KeywordTableInsert(table, "if", TokenType.KIf)	
	KeywordTableInsert(table, "then", TokenType.KThen)	
	KeywordTableInsert(table, "else", TokenType.KElse)	
	KeywordTableInsert(table, "elif", TokenType.KElIf)	
	KeywordTableInsert(table, "while", TokenType.KWhile)	
	KeywordTableInsert(table, "do", TokenType.KDo)	
	KeywordTableInsert(table, "and", TokenType.KAnd)	
	KeywordTableInsert(table, "or", TokenType.KOr)	
	KeywordTableInsert(table, "adt", TokenType.KADT)	
	KeywordTableInsert(table, "match", TokenType.KMatch)	
	KeywordTableInsert(table, "case", TokenType.KCase)	
	KeywordTableInsert(table, "global", TokenType.KGlobal)	

	return table
end

function BuildOperatorTable():OperatorTable
	var table = OperatorTableCreate()
	OperatorTableInsert(table, ".", TokenType.Dot)
	OperatorTableInsert(table, "(", TokenType.LParen)
	OperatorTableInsert(table, ")", TokenType.RParen)
	OperatorTableInsert(table, ":", TokenType.Colon)
	OperatorTableInsert(table, ",", TokenType.Comma)
	OperatorTableInsert(table, "[", TokenType.LBracket)
	OperatorTableInsert(table, "]", TokenType.RBracket)
	
	OperatorTableInsert(table, "=", TokenType.Assign)
	
	OperatorTableInsert(table, "==", TokenType.CmpEQ)
	OperatorTableInsert(table, "<>", TokenType.CmpNE)
	OperatorTableInsert(table, "<", TokenType.CmpLT)
	OperatorTableInsert(table, ">", TokenType.CmpGT)
	OperatorTableInsert(table, "<=", TokenType.CmpLE)
	OperatorTableInsert(table, ">=", TokenType.CmpGE)
	
	OperatorTableInsert(table, "-", TokenType.Minus)
	OperatorTableInsert(table, "+", TokenType.Plus)
	OperatorTableInsert(table, "*", TokenType.Multiply)
	OperatorTableInsert(table, "/", TokenType.Divide)
	return table
end

adt LexerContext
	New
	
	field filename:string
	
	field data:pointer
	field size:i32
	field current:i32
	field tokenStart:i32
	
	field tokenLine:i32
	field tokenCol:i32
	
	field line:i32
	field col:i32
	field lastchar:i32
	
	field tokens:TokenStream
end

adt KeywordTable
	New
	
	field names:string[]
	field tokens:TokenType[]
	field count:i32
end

global Keywords:KeywordTable = BuildKeywordTable()

function KeywordTableInsert(table:KeywordTable, name:string, token:TokenType)
	table.names[table.count] = name
	table.tokens[table.count] = token
	table.count = table.count + 1
end


function TokenStreamCreate():TokenStream
	var ts = TokenStream.New
	ts.capacity = 0
	ts.size = 0
	return ts
end

function TokenStreamAdd(tokens:TokenStream, token:Token)
	if tokens.size == tokens.capacity then
		var newCapacity = tokens.capacity * 2 + 1
		var newArray = new Token[newCapacity]
		var i = 0
		while i < tokens.size do
			newArray[i] = tokens.array[i]
			i = i + 1
		end
		tokens.array = newArray
		tokens.capacity = newCapacity
	end
	
	tokens.array[tokens.size] = token
	tokens.size = tokens.size + 1
end

function peek(lex:LexerContext):i32
	if lex.current >= lex.size then
		return 0-1
	else
		return LoadByte(lex.data, lex.current)
	end
end

function take(lex:LexerContext):i32
	var ret = peek(lex)
	if ret >= 0 then
		lex.current = lex.current + 1
		
		if ret == CharTab then
			lex.col = lex.col + TabSize --tab size
			lex.lastchar = 0
		elif ret == CharNewLine then
			if lex.lastchar == CharCR then
				lex.lastchar = 0
			else
				lex.lastchar = CharNewLine
				lex.col = 0
				lex.line = lex.line + 1
			end
		elif ret == CharCR then
			if lex.lastchar == CharNewLine then
				lex.lastchar = 0
			else
				lex.lastchar = CharCR
				lex.col = 0
				lex.line = lex.line + 1
			end
		else
			lex.col = lex.col + 1
			lex.lastchar = 0
		end
	end
	return ret
end

function LexerCreate():LexerContext
	var lex = LexerContext.New
	lex.tokens = TokenStreamCreate()
	lex.lastchar = 0
	lex.line = 0
	lex.col = 0
	return lex
end

function LexerFeed(lex:LexerContext, filename:string, data:pointer, size:i32)
	lex.filename = filename
	lex.data = data
	lex.size = size
	lex.current = 0
end

adt OperatorTableRef
	Empty
	Table(table:OperatorTable)
end

adt MaybeTokenType
	Nothing
	Just(tt:TokenType)
end

adt OperatorTable
	New
	
	field result:MaybeTokenType
	field advance:OperatorTableRef[]
end

global TabSize:i32 = 4

global CharMinus:i32 = CharCode("-")
global CharTab:i32 = CharCode("\t")
global CharSpace:i32 = CharCode(" ")
global CharNewLine:i32 = CharCode("\n")
global CharCR:i32 = CharCode("\r")

global CharDot:i32 = CharCode(".")
global CharSmallE:i32 = CharCode("e")
global CharCapitalE:i32 = CharCode("E")
global CharPlus:i32 = CharCode("+")

global CharSmallA:i32 = CharCode("a")
global CharSmallZ:i32 = CharCode("z")
global CharCapitalA:i32 = CharCode("A")
global CharCapitalZ:i32 = CharCode("Z")
global CharDig0:i32 = CharCode("0")
global CharDig9:i32 = CharCode("9")

global CharQuote:i32 = CharCode("\"")
global CharBackslash:i32 = CharCode("\\")

global CharUnderscore:i32 = CharCode("_")

global Operators:OperatorTable = BuildOperatorTable()

function OperatorTableCreate():OperatorTable
	var table = OperatorTable.New
	table.result = MaybeTokenType.Nothing
	table.advance = new OperatorTableRef[256]
	var j = 0
	while j < 256 do
		table.advance[j] = OperatorTableRef.Empty
		j = j + 1
	end
	return table
end

function OperatorTableInsert(ops:OperatorTable, s:string, tt:TokenType)
	OperatorTableInsert_helper(ops, s, 0, tt)
end

function OperatorTableInsert_helper(ops:OperatorTable, s:string, i:i32, tt:TokenType)
	if StringLength(s) <= i then
		ops.result = MaybeTokenType.Just(tt)
	else
		var ch = CharAt(s, i)
		match ops.advance[ch]
		case Empty
			var nextTable = OperatorTableCreate()
			ops.advance[ch] = OperatorTableRef.Table(nextTable)
		end
		
		match ops.advance[ch]
		case Table(table)
			OperatorTableInsert_helper(table, s, i + 1, tt)
		end
	end
end

function LexerLexComment(lex:LexerContext)
	while peek(lex) <> CharNewLine and peek(lex) <> CharCR and peek(lex) >= 0 do
		take(lex)
	end
end

function LexerPushToken(lex:LexerContext, tt:TokenType)
	var tok = Token.New
	tok.tt = tt
	tok.loc = SrcLoc.At(lex.tokenLine, lex.tokenCol)
	tok.content = LoadString(lex.data, lex.tokenStart, lex.current - lex.tokenStart)
	TokenStreamAdd(lex.tokens, tok)
end

function LexerError(lex:LexerContext, message:string)
	TokenStreamPrint(lex.tokens)
	
	WriteLn(lex.filename + "(line " + IntToStr(lex.line + 1) + ", col " + IntToStr(lex.col + 1) + "): Lexer Error: " + message)
	
	Exit(1)
end

function isValidIdStart(ch:i32):bool
	return (ch >= CharSmallA and ch <= CharSmallZ) or (ch >= CharCapitalA and ch <= CharCapitalZ) or (ch == CharUnderscore)
end

function isValidIdChar(ch:i32):bool
	return isValidIdStart(ch) or (ch >= CharDig0 and ch <= CharDig9)
end


function LexerLexID(lex:LexerContext)
	take(lex)
	while isValidIdChar(peek(lex)) do
		take(lex)
	end
	LexerPushToken(lex, TokenType.Identifier)
	var lastTokenString = lex.tokens.array[lex.tokens.size - 1].content
	var i = 0
	while i < Keywords.count do
		if Keywords.names[i] == lastTokenString then
			lex.tokens.array[lex.tokens.size - 1].tt = Keywords.tokens[i]
			return
		end
		i = i + 1
	end
end

function LexerLexOperator(lex:LexerContext):bool
	var ch = peek(lex)
	match Operators.advance[ch]
	case Empty
		return false
	end
	
	var ops = Operators
	while true do
		ch = peek(lex)	
		if ch < 0 then
			ch = 0
		end
		match ops.advance[ch]
		case Empty
			match ops.result
			case Nothing
				LexerError(lex, "not an operator")
			case Just(tt)
				LexerPushToken(lex, tt)
			end
			return true
		case Table(nextOps)
			take(lex)
			ops = nextOps
		end
	end
end

function LexerLexString(lex:LexerContext)	
	while true do
		var ch = peek(lex)
		if ch < 0 then
			LexerError(lex, "unexpected eof inside string literal")
			return
		end
		if ch == CharQuote then
			take(lex)
			LexerPushToken(lex, TokenType.StringLiteral)
			return
		end
		if ch == CharBackslash then
			take(lex)
		end
		take(lex)
	end
end

function LexerLexNumber(lex:LexerContext)
	while isDigit(peek(lex)) do
		take(lex)
	end
	
	if peek(lex) == CharDot then
		take(lex)
		while isDigit(peek(lex)) do
			take(lex)
		end
	end
	
	if peek(lex) == CharSmallE or peek(lex) == CharCapitalE then
		take(lex)
		if peek(lex) == CharMinus or peek(lex) == CharPlus then
			take(lex)
		end
		while isDigit(peek(lex)) do
			take(lex)
		end
	end

	LexerPushToken(lex, TokenType.NumberLiteral)
end

function isDigit(ch:i32):bool
	return ch >= CharDig0 and ch <= CharDig9
end

function LexerRun(lex:LexerContext):TokenStream
	while true do
		var ch = peek(lex)
		
		lex.tokenStart = lex.current
		lex.tokenLine = lex.line
		lex.tokenCol = lex.col
		
		if ch < 0 then
			LexerPushToken(lex, TokenType.EOF)
			return lex.tokens
		end
		
		
		if ch == CharNewLine or ch == CharCR or ch == CharSpace or ch == CharTab then
			--newlines, tabs and spaces
			take(lex)
		elif ch == CharMinus then
			--minus and comment
			take(lex)
			if peek(lex) == CharMinus then
				take(lex)
				LexerLexComment(lex)
			else
				LexerPushToken(lex, TokenType.Minus)
			end
		elif ch == CharQuote then
			--string literal
			take(lex)
			LexerLexString(lex)
		elif isDigit(ch) then
			--number literal
			LexerLexNumber(lex)
		elif isValidIdStart(ch) then	
			--identifiers and keywords
			LexerLexID(lex)
		elif LexerLexOperator(lex) then
			--operators
		else
			LexerError(lex, "Unexpected character")
		end
	end
end

function TokenStreamPrint(tokens:TokenStream)
	var i = 0
	while i < tokens.size do
		if i > 0 then
			Write(" ")
		end
		
		Write("<" + TokenGetName(tokens.array[i]) + ">")
		
		i = i + 1
	end
	WriteLn("")
end
